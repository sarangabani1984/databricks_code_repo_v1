{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d481b64-ee80-41e4-9d82-ea1fb4d7bab7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "####2. Programatically try to find couple of data patterns applying below EDA (File: logistics_source1)\n",
    "1. Apply inferSchema and toDF to create a DF and analyse the actual data.\n",
    "2. Analyse the schema, datatypes, columns etc.,\n",
    "3. Analyse the duplicate records count and summary of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a33982d-310b-4456-b4e7-4f4556d5b47a",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1768397588182}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw1=spark.read.csv(\"/Volumes/lakehouse1/dbread/read_volume/logistics/logistics_source1\",header=True,inferSchema=True).toDF(\"ShipmentId\",\"FirstName\",\"LastName\",\"Age\",\"Role\")\n",
    "display(raw1)\n",
    "raw1.printSchema()\n",
    "print(raw1.dtypes)\n",
    "print(raw1.columns)\n",
    "raw1.count()\n",
    "display(raw1.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f01451f-a196-4c03-a3cc-5d5961e09509",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Analyse the duplicate records count and summary of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d17fcbe2-b6d8-49ab-aef3-7e2e448e80d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw1.groupBy(\n",
    "        \"shipmentId\"\n",
    ").count().filter(\"count > 1\").show()\n",
    "\n",
    "raw1.groupBy(\n",
    "        \"FirstName\"\n",
    ").count().filter(\"count > 1\").show()\n",
    "\n",
    "raw1.groupBy(\n",
    "        \"lastName\"\n",
    ").count().filter(\"count > 1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e6a3c7d-5cc7-4180-8d99-64c32932853e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "column level dupicate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c57c665-c149-40fc-a5c6-5c3e3634e230",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "raw1.groupBy(\n",
    "    \"ShipmentId\",\n",
    "    \"FirstName\",\n",
    "    \"LastName\",\n",
    "    \"Age\",\n",
    "    \"Role\"\n",
    ").count().filter(\"count > 1\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d71ff1ac-1fc0-4297-bb1e-79711db19e2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###a. Passive Data Munging -  (File: logistics_source1  and logistics_source2)\n",
    "Without modifying the data, identify:<br>\n",
    "Shipment IDs that appear in both master_v1 and master_v2<br>\n",
    "Records where:<br>\n",
    "1. shipment_id is non-numeric\n",
    "2. age is not an integer<br>\n",
    "Count rows having:\n",
    "3. fewer columns than expected\n",
    "4. more columns than expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e23e1e3-ba6c-484d-8668-a065a34b3c04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "master_v1 = spark.read.option(\"header\", True).csv(\n",
    "    \"/Volumes/lakehouse1/dbread/read_volume/logistics/logistics_source1\"\n",
    ")\n",
    "\n",
    "master_v2 = spark.read.option(\"header\", True).csv(\n",
    "    \"/Volumes/lakehouse1/dbread/read_volume/logistics/logistics_source2\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4f3639d-33d5-4cee-a473-49a64e131586",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "common_shipments = (\n",
    "    master_v1.select(col(\"shipment_id\")).distinct()\n",
    "    .intersect(master_v2.select(col(\"shipment_id\")).distinct())\n",
    ")\n",
    "\n",
    "display(common_shipments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "589b29ed-6abc-4f7a-87b8-c8ccd2b102ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "non_numeric_shipmentid = master_v1.filter(\n",
    "    ~F.col(\"shipment_id\").rlike(\"^[0-9]+$\")\n",
    ")\n",
    "\n",
    "non_numeric_shipmentid.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "BB2_Usecase",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
